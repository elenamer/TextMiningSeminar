{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import collections\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook BERT Kaggle Notebook.ipynb to script\n",
      "[NbConvertApp] Writing 5506 bytes to BERT Kaggle Notebook.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script \"BERT Kaggle Notebook.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT = .15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "texts = []\n",
    "\n",
    "# read full dataset file\n",
    "with open(\"../articles.csv\",  \"r\", encoding='utf-8',) as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=';', quotechar='\\'')\n",
    "    for row in reader:\n",
    "        labels.append(row[0])\n",
    "        texts.append(row[1])\n",
    "\n",
    "tr_Df=pd.concat([pd.Series(texts, name=\"Text\"), pd.Series(labels,name='Label')], axis=1)\n",
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split( tr_Df['Text'], tr_Df['Label'], test_size=SPLIT, random_state=42,stratify=tr_Df['Label'])\n",
    "\n",
    "# write train and test datasets\n",
    "train=pd.DataFrame(pd.concat([X_train,y_train],axis=1))\n",
    "test=pd.DataFrame(pd.concat([X_test,y_test],axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9321</th>\n",
       "      <td>Die Energiewirtschaft hat ihre Strategie bis 2...</td>\n",
       "      <td>Wirtschaft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>Östereich siegte in Podgorica zuerst gegen 12,...</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8630</th>\n",
       "      <td>Sagis Vertreter Phillip Burns und Barry Gilber...</td>\n",
       "      <td>Wirtschaft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Keine offizielle Bestätigung über Verhandlungs...</td>\n",
       "      <td>Etat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>Roland Düringer in Autorevue TV, vom Leiden de...</td>\n",
       "      <td>Etat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>Auch Einreise- und Vermögenssperren gegen Luka...</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5236</th>\n",
       "      <td>In der chinesischen Hauptstadt fahren Österrei...</td>\n",
       "      <td>Panorama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Strache will weltoffen sein, atmete man in dem...</td>\n",
       "      <td>Etat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5186</th>\n",
       "      <td>25-Jähriger wollte TV-Sender mit Sprengstoffgü...</td>\n",
       "      <td>Panorama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>Linz übernimmt nach Sieg in Innsbruck die Spit...</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3081 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text          Label\n",
       "9321  Die Energiewirtschaft hat ihre Strategie bis 2...     Wirtschaft\n",
       "5703  Östereich siegte in Podgorica zuerst gegen 12,...          Sport\n",
       "8630  Sagis Vertreter Phillip Burns und Barry Gilber...     Wirtschaft\n",
       "44    Keine offizielle Bestätigung über Verhandlungs...           Etat\n",
       "537   Roland Düringer in Autorevue TV, vom Leiden de...           Etat\n",
       "...                                                 ...            ...\n",
       "2184  Auch Einreise- und Vermögenssperren gegen Luka...  International\n",
       "5236  In der chinesischen Hauptstadt fahren Österrei...       Panorama\n",
       "220   Strache will weltoffen sein, atmete man in dem...           Etat\n",
       "5186  25-Jähriger wollte TV-Sender mit Sprengstoffgü...       Panorama\n",
       "6466  Linz übernimmt nach Sieg in Innsbruck die Spit...          Sport\n",
       "\n",
       "[3081 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = KeyedVectors.load_word2vec_format('./models/wiki.de.align.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"der\",\"die\",\"das\",\"den\",\"des\",\"dem\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Tokenizes the provided text\n",
    "    Args:\n",
    "        text (str): The text to be tokenized\n",
    "    Returns:\n",
    "        list(tuple(str, int)): A list of (token, count) pairs from the text without the stopwords.\n",
    "    \"\"\"\n",
    "\n",
    "    # make everything lowercase and strip punctuation\n",
    "    CUSTOM_FILTERS = [lambda x: x.lower(), strip_punctuation]\n",
    "    tokens = preprocess_string(text, CUSTOM_FILTERS)\n",
    "\n",
    "    # filter out all stopwords\n",
    "    filtered_tokens = [w for w in tokens if not w in stopwords]\n",
    "\n",
    "    # return the filtered tokens\n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_embedding(text):\n",
    "    \"\"\"Create the text embedding\n",
    "    Args:\n",
    "        text (str): The text to be embedded\n",
    "    Returns:\n",
    "        list(float): The array of values representing the text embedding\n",
    "    \"\"\"\n",
    "\n",
    "    # prepare the embedding placeholder\n",
    "    embedding = np.zeros(embeddings.vector_size, dtype=np.float32)\n",
    "\n",
    "    if text is None:\n",
    "        # return the default embedding in a vanilla python object\n",
    "        return embedding\n",
    "\n",
    "    # get the text terms with frequencies\n",
    "    tokens = tokenize(text)\n",
    "    # iterate through the terms and count the number of terms\n",
    "    count = 0\n",
    "    for token in tokens:\n",
    "        # sum all token embeddings of the vector\n",
    "        if token in embeddings.vocab.keys():\n",
    "            embedding += embeddings[token]\n",
    "            count += 1\n",
    "\n",
    "    if count == 0:\n",
    "        # return the empty embedding list\n",
    "        return embedding.tolist()\n",
    "\n",
    "    # average the embedding\n",
    "    embedding = embedding / count\n",
    "\n",
    "\n",
    "    # return the embedding in vanilla python object\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"elena\")\n",
    "print(embeddings.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embds=[]\n",
    "for ind in train.index.values:\n",
    "    embds.append(text_embedding(X_train.loc[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embds=np.stack( embds, axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=15, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=15)\n",
    "clf.fit(embds,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9985112061121956"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(clf.predict(embds),y_train, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embds_test=[]\n",
    "for ind in test.index.values:\n",
    "    embds_test.append(text_embedding(X_test.loc[ind]))\n",
    "embds=np.stack( embds, axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8096601263256422"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(clf.predict(embds_test),y_test, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8092147955872809"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(embds_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['International' 'Wirtschaft' 'Wirtschaft' ... 'Wirtschaft' 'Wirtschaft'\n",
      " 'Web']\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(embds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elena-carica/anaconda3/envs/embeddings/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:938: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8554687254024944"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf=LogisticRegression(C=1000)\n",
    "clf.fit(embds,y_train)\n",
    "f1_score(clf.predict(embds),y_train, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8492762019674748"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(clf.predict(embds_test),y_test, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
