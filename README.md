# TextMiningSeminar

## Prerequisites

Python version 3.8 or higher

## Create the Conda environment

```python
# create the environment with the required packages
conda env create -f environment.yml
# to activate the conda environment run
conda activate tm-seminar-elena-env
```

## Extract the data 

Download the corpus.sqlite3 file into the project root from [here](https://github.com/tblock/10kGNAD/releases/download/v1.0/corpus.sqlite3)

Run ```bash python code/extract_dataset_from_sqlite.py corpus.sqlite3 articles.csv``` to extract the articles.

## Folder structure

| Folder   |      Description      | 
|----------|-------------|
| code     |    script to extract the data    |
|Notebooks |   notebooks, which calculate the embeddings and run classifiers |
|Notebooks/models |  fasttext model file |
|Notebooks/features |  files containing the embeddings generated by BERT and Fasttext notebooks |
|Notebooks/results_with_scaling_default |  files with results from all experiment settings (confusion matrix and f1 score and accuracy) |
| visualizations | images and tables to evaluate results | 
